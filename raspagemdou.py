# -*- coding: utf-8 -*-
"""
DOU ‚Äì raspagem di√°ria com duas sa√≠das:
1) Planilha geral (aba "P√°gina1"):
   Data | Palavra-chave | Portaria | Link | Resumo | Conte√∫do
2) Planilha por cliente (uma aba por sigla):
   Data | Cliente | Palavra-chave | Portaria | Link | Resumo | Conte√∫do

Observa√ß√£o:
- A coluna "Conte√∫do" SEMPRE √© preenchida automaticamente com o texto da p√°gina do DOU.
- Limite padr√£o de caracteres = 3000 (mude com env DOU_CONTEUDO_MAX).

Este arquivo inclui bloqueio de men√ß√µes ao Conselho Regional de Educa√ß√£o F√≠sica (CREF/CONFEF)
e envio de e-mail agrupado por cliente/palavra-chave.
"""

import os, re, json, unicodedata, requests, gspread
from bs4 import BeautifulSoup
from datetime import datetime
from google.oauth2.service_account import Credentials

# ======= E-mail (Brevo) =======
from brevo_python import ApiClient, Configuration
from brevo_python.api.transactional_emails_api import TransactionalEmailsApi
from brevo_python.models.send_smtp_email import SendSmtpEmail
from brevo_python.rest import ApiException

# ============================================================
# Normaliza√ß√£o + busca whole-word
# ============================================================
def _normalize(s: str) -> str:
    if s is None:
        return ""
    t = unicodedata.normalize("NFD", str(s))
    t = "".join(c for c in t if unicodedata.category(c) != "Mn")
    return t.lower()

def _normalize_ws(s: str) -> str:
    return re.sub(r'[^a-z0-9]+', ' ', _normalize(s)).strip()

def _wholeword_pattern(phrase: str):
    toks = [t for t in _normalize_ws(phrase).split() if t]
    if not toks:
        return None
    return re.compile(r'\b' + r'\s+'.join(map(re.escape, toks)) + r'\b')

# ============================================================
# BLOQUEIO DE MEN√á√ïES (CREF/CONFEF)
# ============================================================
EXCLUDE_PATTERNS = [
    _wholeword_pattern("Conselho Regional de Educa√ß√£o F√≠sica"),
    _wholeword_pattern("Conselho Regional de Educacao Fisica"),  # sem acento
    re.compile(r"\bCREF\b", re.I),    # opcional: bloqueia sigla
    re.compile(r"\bCONFEF\b", re.I),  # opcional: conselho federal
]

def _is_blocked(text: str) -> bool:
    """Retorna True se o texto contiver men√ß√µes bloqueadas."""
    if not text:
        return False
    nt = _normalize_ws(text)
    for pat in EXCLUDE_PATTERNS:
        if pat and pat.search(nt):
            return True
    return False

# ============================================================
# Coleta do conte√∫do completo da p√°gina do DOU (sempre ligada)
# ============================================================
CONTEUDO_MAX = int(os.getenv("DOU_CONTEUDO_MAX", "49500"))  # limite de caracteres
_CONTENT_CACHE: dict[str, str] = {}

_HDR = {
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
                  "(KHTML, like Gecko) Chrome/126 Safari/537.36"
}

def _baixar_conteudo_pagina(url: str) -> str:
    if not url:
        return ""
    if url in _CONTENT_CACHE:
        return _CONTENT_CACHE[url]
    try:
        r = requests.get(url, timeout=40, headers=_HDR)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")

        # remove scripts/estilos
        for t in soup(["script", "style", "noscript"]):
            t.decompose()

        # 1) layout t√≠pico do DOU: article#materia > div.texto-dou
        bloco = soup.select_one("article#materia div.texto-dou") or soup.select_one("div.texto-dou")
        if bloco:
            ps = []
            for p in bloco.find_all(["p", "li"]):
                cls = set(p.get("class") or [])
                if {"dou-paragraph", "identifica", "ementa"} & cls or p.name == "li":
                    txt = p.get_text(" ", strip=True)
                    if txt:
                        ps.append(txt)
            if ps:
                txt = "\n\n".join(ps)
                txt = re.sub(r"[ \t]+", " ", txt).strip()
                if CONTEUDO_MAX and len(txt) > CONTEUDO_MAX:
                    txt = txt[:CONTEUDO_MAX] + "‚Ä¶"
                _CONTENT_CACHE[url] = txt
                return txt

        # 2) outros cont√™ineres comuns do portal (fallback)
        sels = [
            "div.single-content", "div.article-content", "article",
            "div#content-core", "div#content", "section#content"
        ]
        textos = []
        for sel in sels:
            el = soup.select_one(sel)
            if not el:
                continue
            ps = [p.get_text(" ", strip=True) for p in el.find_all(["p", "li"]) if p.get_text(strip=True)]
            if len(ps) >= 2:
                textos.append("\n\n".join(ps))
            else:
                textos.append(el.get_text(" ", strip=True))

        txt = max(textos, key=len) if textos else soup.get_text(" ", strip=True)
        txt = re.sub(r"[ \t]+", " ", txt).strip()
        if CONTEUDO_MAX and len(txt) > CONTEUDO_MAX:
            txt = txt[:CONTEUDO_MAX] + "‚Ä¶"
        _CONTENT_CACHE[url] = txt
        return txt
    except Exception:
        return ""
       
# ============================================================
# Raspagem do DOU (capa do dia)
# ============================================================
def raspa_dou(data=None):
    if data is None:
        data = datetime.now().strftime('%d-%m-%Y')
    print(f'Raspando as not√≠cias do dia {data}...')
    try:
        url = f'http://www.in.gov.br/leiturajornal?data={data}'
        page = requests.get(url, timeout=40, headers=_HDR)
        page.raise_for_status()
        soup = BeautifulSoup(page.text, 'html.parser')
        params = soup.find("script", {"id": "params"})
        if params:
            print('Not√≠cias raspadas.')
            return json.loads(params.text)
        print("Elemento <script id='params'> n√£o encontrado.")
        return None
    except requests.RequestException as e:
        print(f"Erro ao fazer a requisi√ß√£o: {e}")
        return None
    except json.JSONDecodeError as e:
        print(f"Erro ao decodificar JSON: {e}")
        return None

# ============================================================
# Palavras gerais (planilha geral)
# ============================================================
PALAVRAS_GERAIS = [
    'Inf√¢ncia','Crian√ßa','Infantil','Inf√¢ncias','Crian√ßas',
    'Educa√ß√£o','Ensino','Escolaridade',
    'Plano Nacional da Educa√ß√£o','PNE','Educacional',
    'Alfabetiza√ß√£o','Letramento',
    'Sa√∫de','Telessa√∫de','Telemedicina',
    'Digital','Digitais','Prontu√°rio',
    'Programa Sa√∫de na Escola','PSE',
    'Psicosocial','Mental','Sa√∫de Mental','Dados para a Sa√∫de','Morte Evit√°vel',
    'Doen√ßas Cr√¥nicas N√£o Transmiss√≠veis','Rotulagem de Bebidas Alco√≥licas',
    'Educa√ß√£o em Sa√∫de','Bebidas Alco√≥licas','Imposto Seletivo',
    'Rotulagem de Alimentos','Alimentos Ultraprocessados',
    'Publicidade Infantil','Publicidade de Alimentos Ultraprocessados',
    'Tributa√ß√£o de Bebidas Alco√≥licas','Al√≠quota de Bebidas Alco√≥licas',
    'Cigarro Eletr√¥nico','Controle de Tabaco','Viol√™ncia Dom√©stica',
    'Exposi√ß√£o a Fatores de Risco','Departamento de Sa√∫de Mental',
    'Hipertens√£o Arterial','Alimenta√ß√£o Escolar','PNAE','Agora Tem Especialistas',
    # Alfabetiza√ß√£o
    'Alfabetiza√ß√£o','Alfabetiza√ß√£o na Idade Certa','Crian√ßa Alfabetizada','Meta de Alfabetiza√ß√£o',
    'Plano Nacional de Alfabetiza√ß√£o','Programa Crian√ßa Alfabetizada','Idade Certa para Alfabetiza√ß√£o',
    'Alfabetiza√ß√£o de Crian√ßas','Alfabetiza√ß√£o Inicial','Alfabetiza√ß√£o Plena',
    'Alfabetiza√ß√£o em L√≠ngua Portuguesa','Analfabetismo','Erradica√ß√£o do Analfabetismo',
    'Programa Nacional de Alfabetiza√ß√£o na Idade Certa','Pacto pela Alfabetiza√ß√£o',
    'Pol√≠tica Nacional de Alfabetiza√ß√£o','Recomposi√ß√£o das Aprendizagens em Alfabetiza√ß√£o',
    'Compet√™ncias de Alfabetiza√ß√£o','Avalia√ß√£o da Alfabetiza√ß√£o','Saeb Alfabetiza√ß√£o',
    # Matem√°tica
    'Alfabetiza√ß√£o Matem√°tica','Analfabetismo Matem√°tico','Aprendizagem em Matem√°tica',
    'Recomposi√ß√£o das Aprendizagens em Matem√°tica','Recomposi√ß√£o de Aprendizagem',
    'Compet√™ncias Matem√°ticas','Profici√™ncia em Matem√°tica',
    'Avalia√ß√£o Diagn√≥stica de Matem√°tica','Avalia√ß√£o Formativa de Matem√°tica',
    'Pol√≠tica Nacional de Matem√°tica','Saeb Matem√°tica','Ideb Matem√°tica','BNCC Matem√°tica',
    'Matem√°tica no Ensino Fundamental','Matem√°tica no Ensino M√©dio',
    'Anos Iniciais de Matem√°tica','Anos Finais de Matem√°tica','OBMEP',
    'Olimp√≠ada Brasileira de Matem√°tica das Escolas P√∫blicas','Olimp√≠ada de Matem√°tica','PNLD Matem√°tica'
]
_PATTERNS_GERAL = [(kw, _wholeword_pattern(kw)) for kw in PALAVRAS_GERAIS]

def procura_termos(conteudo_raspado):
    """
    Planilha geral ‚Äî Data | Palavra-chave | Portaria | Link | Resumo | Conte√∫do
    """
    if conteudo_raspado is None or 'jsonArray' not in conteudo_raspado:
        print('Nenhum conte√∫do para analisar (geral).')
        return None

    print('Buscando palavras-chave (geral, whole-word, t√≠tulo+resumo)...')
    URL_BASE = 'https://www.in.gov.br/en/web/dou/-/'
    resultados_por_palavra = {palavra: [] for palavra in PALAVRAS_GERAIS}
    algum = False

    for resultado in conteudo_raspado['jsonArray']:
        titulo   = resultado.get('title', 'T√≠tulo n√£o dispon√≠vel')
        resumo   = resultado.get('content', '')
        link     = URL_BASE + resultado.get('urlTitle', '')
        data_pub = (resultado.get('pubDate', '') or '')[:10]

        # corta cedo se t√≠tulo/resumo j√° indicarem men√ß√£o bloqueada
        if _is_blocked(titulo + " " + resumo):
            continue

        texto_norm = _normalize_ws(titulo + " " + resumo)
        conteudo_pagina = None  # baixa apenas se houver match

        for palavra, patt in _PATTERNS_GERAL:
            if patt and patt.search(texto_norm):
                if conteudo_pagina is None:
                    conteudo_pagina = _baixar_conteudo_pagina(link)
                # corta se o conte√∫do completo tiver men√ß√£o bloqueada
                if _is_blocked(conteudo_pagina):
                    continue
                resultados_por_palavra[palavra].append({
                    'date': data_pub,
                    'title': titulo,
                    'href': link,
                    'abstract': resumo,
                    'content_page': conteudo_pagina
                })
                algum = True

    if not algum:
        print('Nenhum resultado encontrado (geral).')
        return None
    print('Palavras-chave (geral) encontradas.')
    return resultados_por_palavra

# ============================================================
# Cliente ‚Üí Palavras (whole-word)
# ============================================================
CLIENT_THEME_DATA = """
IAS|Educa√ß√£o|Matem√°tica; Alfabetiza√ß√£o; Alfabetiza√ß√£o Matem√°tica; Recomposi√ß√£o de aprendizagem; Plano Nacional de Educa√ß√£o
ISG|Educa√ß√£o|Tempo Integral; Ensino em tempo integral; Ensino Profissional e Tecnol√≥gico; Fundeb; PROPAG; Educa√ß√£o em tempo integral; Escola em tempo integral; Plano Nacional de Educa√ß√£o; Programa escola em tempo integral; Programa P√©-de-meia; PNEERQ; INEP; FNDE; Conselho Nacional de Educa√ß√£o; PDDE; Programa de Fomento √†s Escolas de Ensino M√©dio em Tempo Integral; Celular nas escolas; Juros da Educa√ß√£o
IU|Educa√ß√£o|Gest√£o Educacional; Diretores escolares; Magist√©rio; Professores ensino m√©dio; Sindicatos de professores; Ensino M√©dio; Fundeb; Adapta√ß√µes de Escolas; Educa√ß√£o Ambiental; Plano Nacional de Educa√ß√£o; PDDE; Programa P√© de Meia; INEP; FNDE; Conselho Nacional de Educa√ß√£o; VAAT; VAAR; Secretaria Estadual de Educa√ß√£o; Celular nas escolas; EAD; Juro da educa√ß√£o; Recomposi√ß√£o de Aprendizagem
Re√∫na|Educa√ß√£o|Matem√°tica; Alfabetiza√ß√£o; Alfabetiza√ß√£o Matem√°tica; Recomposi√ß√£o de aprendizagem; Plano Nacional de Educa√ß√£o; Emendas parlamentares educa√ß√£o
REMS|Esportes|Esporte amador; Esporte para toda a vida; Esporte e desenvolvimento social; Financiamento do esporte; Lei de Incentivo ao Esporte; Plano Nacional de Esporte; Conselho Nacional de Esporte; Emendas parlamentares esporte
FMCSV|Primeira inf√¢ncia|Crian√ßa; Inf√¢ncia; infanto-juvenil; educa√ß√£o b√°sica; PNE; FNDE; Fundeb; VAAR; VAAT; educa√ß√£o infantil; maternidade; paternidade; alfabetiza√ß√£o; creche; pr√©-escola; parentalidade; materno-infantil; infraestrutura escolar; pol√≠tica nacional de cuidados; Plano Nacional de Educa√ß√£o; Bolsa Fam√≠lia; Conanda; visita√ß√£o domiciliar; Homeschooling; Pol√≠tica Nacional Integrada da Primeira Inf√¢ncia
IEPS|Sa√∫de|SUS; Sistema √önico de Sa√∫de; fortalecimento; Universalidade; Equidade em sa√∫de; popula√ß√µes vulner√°veis; desigualdades sociais; Organiza√ß√£o do SUS; gest√£o p√∫blica; pol√≠ticas p√∫blicas em sa√∫de; Governan√ßa do SUS; regionaliza√ß√£o; descentraliza√ß√£o; Regionaliza√ß√£o em sa√∫de; Pol√≠ticas p√∫blicas em sa√∫de; Popula√ß√£o negra em sa√∫de; Sa√∫de ind√≠gena; Povos origin√°rios; Sa√∫de da pessoa idosa; envelhecimento ativo; Aten√ß√£o Prim√°ria; Sa√∫de da crian√ßa; Sa√∫de do adolescente; Sa√∫de da mulher; Sa√∫de do homem; Sa√∫de da pessoa com defici√™ncia; Sa√∫de da popula√ß√£o LGBTQIA+; Financiamento da sa√∫de; aten√ß√£o prim√°ria; tripartite; or√ßamento; Emendas e or√ßamento da sa√∫de; Minist√©rio da Sa√∫de; Trabalhadores de sa√∫de; For√ßa de trabalho em sa√∫de; Recursos humanos em sa√∫de; Forma√ß√£o profissional de sa√∫de; Cuidados prim√°rios em sa√∫de; Emerg√™ncias clim√°ticas e ambientais em sa√∫de; mudan√ßas clim√°ticas; adapta√ß√£o clim√°tica; sa√∫de ambiental; pol√≠ticas clim√°ticas; Vigil√¢ncia em sa√∫de; epidemiol√≥gica; Emerg√™ncia em sa√∫de; estado de emerg√™ncia; Sa√∫de suplementar; complementar; privada; planos de sa√∫de; seguros; seguradoras; planos populares; Anvisa; gest√£o; governan√ßa; ANS; Sandbox regulat√≥rio; Cart√µes e administradoras de benef√≠cios em sa√∫de; Economia solid√°ria em sa√∫de mental; Pessoa em situa√ß√£o de rua; sa√∫de mental; Fiscaliza√ß√£o de comunidades terap√™uticas; Rede de aten√ß√£o psicossocial; RAPS; unidades de acolhimento; assist√™ncia multiprofissional; centros de conviv√™ncia; Cannabis; canabidiol; tratamento terap√™utico; Desinstitucionaliza√ß√£o; manic√¥mios; hospitais de cust√≥dia; Sa√∫de mental na inf√¢ncia; adolesc√™ncia; escolas; comunidades escolares; protagonismo juvenil; Depend√™ncia qu√≠mica; v√≠cios; ludopatia; Treinamento em sa√∫de mental; capacita√ß√£o em sa√∫de mental; Interven√ß√µes terap√™uticas em sa√∫de mental; Internet e redes sociais na sa√∫de mental; Viol√™ncia psicol√≥gica; Surto psic√≥tico
Manual|Sa√∫de|Ozempic; Wegovy; Mounjaro; Telemedicina; Telessa√∫de; CBD; Cannabis Medicinal; CFM; Conselho Federal de Medicina; Farm√°cia Magistral; Medicamentos Manipulados; Minoxidil; Emagrecedores; Reten√ß√£o de receita de medicamentos
Mevo|Sa√∫de|Prontu√°rio eletr√¥nico; dispensa√ß√£o eletr√¥nica; telessa√∫de; assinatura digital; certificado digital; controle sanit√°rio; prescri√ß√£o por enfermeiros; doen√ßas cr√¥nicas; autonomia da ANPD; Acesso e uso de dados; responsabiliza√ß√£o de plataformas digitais; regulamenta√ß√£o de marketplaces; seguran√ßa cibern√©tica; intelig√™ncia artificial; digitaliza√ß√£o do SUS; venda de medicamentos; distribui√ß√£o de medicamentos; Bula digital; Atesta CFM; SNGPC; Farmac√™utico Remoto; Medicamentos Isentos de Prescri√ß√£o; MIPs; RNDS; Rede Nacional de Dados em Sa√∫de
Giro de not√≠cias|Temas gerais para o Giro de Not√≠cias e clipping cactus|Governo Lula; Presidente Lula; Governo; Governo Federal; Governo economia; Economia; Governo internacional; Sa√∫de; Medicamento; Vacina; C√¢ncer; Oncologia; Gripe; Diabetes; Obesidade; Alzheimer; Sa√∫de mental; S√≠ndrome respirat√≥ria; SUS; Sistema √önico de Sa√∫de; Minist√©rio da Sa√∫de; Alexandre Padilha; ANVISA; Primeira Inf√¢ncia; Inf√¢ncia; Crian√ßa; Sa√∫de crian√ßa; Sa√∫de infantil; cuidado crian√ßa; legisla√ß√£o crian√ßa; direitos da crian√ßa; crian√ßa c√¢mara; crian√ßa senado; alfabetiza√ß√£o; creche; minist√©rio da educa√ß√£o; educa√ß√£o; educa√ß√£o Brasil; escolas; aprendizado; ensino integral; ensino m√©dio; Camilo Santana
Cactus|Sa√∫de|Sa√∫de mental; sa√∫de mental para meninas; sa√∫de mental para juventude; sa√∫de mental para mulheres; Rede de aten√ß√£o psicossocial; RAPS; CAPS; Centro de Apoio Psicossocial
Vital Strategies|Sa√∫de|Sa√∫de mental; Dados para a sa√∫de; Morte evit√°vel; Doen√ßas cr√¥nicas n√£o transmiss√≠veis; Rotulagem de bebidas alco√≥licas; Educa√ß√£o em sa√∫de; Bebidas alco√≥licas; Imposto seletivo; Rotulagem de alimentos; Alimentos ultraprocessados; Publicidade infantil; Publicidade de alimentos ultraprocessados; Tributa√ß√£o de bebidas alco√≥licas; Al√≠quota de bebidas alco√≥licas; Cigarro eletr√¥nico; Controle de tabaco; Viol√™ncia dom√©stica; Exposi√ß√£o a fatores de risco; Departamento de Sa√∫de Mental; Hipertens√£o arterial; Sa√∫de digital; Viol√™ncia contra crian√ßas; Viol√™ncia contra mulheres; Feminic√≠dio; COP 30
""".strip()

def _parse_client_keywords(text: str):
    out = {}
    for line in text.splitlines():
        if not line.strip():
            continue
        cliente, tema, kws = [x.strip() for x in line.split("|", 2)]
        out.setdefault(cliente, [])
        for kw in [k.strip() for k in kws.split(";") if k.strip()]:
            if kw not in out[cliente]:
                out[cliente].append(kw)
    return out

CLIENT_KEYWORDS = _parse_client_keywords(CLIENT_THEME_DATA)

# pr√©-compila padr√µes por cliente
CLIENT_PATTERNS = []  # (regex, cliente, kw_original)
for cli, kws in CLIENT_KEYWORDS.items():
    for kw in kws:
        pat = _wholeword_pattern(kw)
        if pat:
            CLIENT_PATTERNS.append((pat, cli, kw))

def procura_termos_clientes(conteudo_raspado):
    """
    Retorna dict cliente -> [rows] onde cada row √©:
    [Data, Cliente, Palavra-chave, Portaria, Link, Resumo, Conte√∫do]
    (uma linha por palavra-chave encontrada por cliente)
    """
    if conteudo_raspado is None or 'jsonArray' not in conteudo_raspado:
        print('Nenhum conte√∫do para analisar (clientes).')
        return {}

    print('Buscando palavras-chave por cliente (whole-word, t√≠tulo+resumo)...')
    URL_BASE = 'https://www.in.gov.br/en/web/dou/-/'
    por_cliente = {c: [] for c in CLIENT_KEYWORDS.keys()}

    for r in conteudo_raspado['jsonArray']:
        titulo   = r.get('title', 'T√≠tulo n√£o dispon√≠vel')
        resumo   = r.get('content', '')
        link     = URL_BASE + r.get('urlTitle', '')
        data_pub = (r.get('pubDate', '') or '')[:10]

        # corta cedo por t√≠tulo/resumo
        if _is_blocked(titulo + " " + resumo):
            continue

        texto_norm = _normalize_ws(titulo + " " + resumo)
        conteudo_pagina = None
        for pat, cliente, kw in CLIENT_PATTERNS:
            if pat.search(texto_norm):
                if conteudo_pagina is None:
                    conteudo_pagina = _baixar_conteudo_pagina(link)
                # corta por conte√∫do completo
                if _is_blocked(conteudo_pagina):
                    continue
                por_cliente[cliente].append([data_pub, cliente, kw, titulo, link, resumo, conteudo_pagina])
    return por_cliente

# ============================================================
# Google Sheets helpers
# ============================================================
def _gs_client_from_env():
    raw = os.getenv("GOOGLE_APPLICATION_CREDENTIALS_JSON")
    if not raw:
        # fallback: se j√° criou credentials.json no workflow
        jf = "credentials.json"
        if os.path.exists(jf):
            scopes = ["https://www.googleapis.com/auth/spreadsheets","https://www.googleapis.com/auth/drive"]
            creds = Credentials.from_service_account_file(jf, scopes=scopes)
            return gspread.authorize(creds)
        raise RuntimeError("Secret GOOGLE_APPLICATION_CREDENTIALS_JSON n√£o encontrado.")
    info = json.loads(raw)
    if "private_key" in info and "\\n" in info["private_key"]:
        info["private_key"] = info["private_key"].replace("\\n", "\n")
    scopes = ["https://www.googleapis.com/auth/spreadsheets","https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_info(info, scopes=scopes)
    return gspread.authorize(creds)

# ---- Colunas FIXAS (Conte√∫do √© sempre a √∫ltima)
COLS_GERAL   = ["Data","Palavra-chave","Portaria","Link","Resumo","Conte√∫do"]
COLS_CLIENTE = ["Data","Cliente","Palavra-chave","Portaria","Link","Resumo","Conte√∫do"]

def _ensure_header(ws, header):
    first = ws.row_values(1)
    if first != header:
        ws.resize(rows=max(2, ws.row_count), cols=len(header))
        ws.update('1:1', [header])

# ---- Geral
def salva_na_base(palavras_raspadas):
    if not palavras_raspadas:
        print('Sem palavras encontradas para salvar (geral).')
        return
    print('Salvando (geral) na planilha...')

    gc = _gs_client_from_env()
    planilha_id = os.getenv('PLANILHA')
    if not planilha_id:
        raise RuntimeError("Env PLANILHA n√£o definido (use apenas a key entre /d/ e /edit).")

    sh = gc.open_by_key(planilha_id)
    try:
        ws = sh.worksheet('P√°gina1')
    except gspread.WorksheetNotFound:
        ws = sh.add_worksheet(title='P√°gina1', rows="2000", cols=str(len(COLS_GERAL)))
    _ensure_header(ws, COLS_GERAL)

    rows_to_append = []
    for palavra, lista in (palavras_raspadas or {}).items():
        for item in lista:
            row = [
                item.get('date',''),
                palavra,
                item.get('title',''),
                item.get('href',''),
                item.get('abstract',''),
                item.get('content_page','')
            ]
            rows_to_append.append(row)

    if rows_to_append:
        ws.insert_rows(rows_to_append, row=2, value_input_option='USER_ENTERED')
        print(f"{len(rows_to_append)} linhas adicionadas (geral).")
    else:
        print('Nenhum dado v√°lido para salvar (geral).')

# ---- Por cliente
def _append_dedupe_por_cliente(sh, sheet_name: str, rows: list[list[str]]):
    if not rows:
        print(f"[{sheet_name}] sem linhas para anexar.")
        return
    try:
        ws = sh.worksheet(sheet_name)
    except gspread.WorksheetNotFound:
        ws = sh.add_worksheet(title=sheet_name, rows=str(max(100, len(rows)+10)), cols=len(COLS_CLIENTE))
    _ensure_header(ws, COLS_CLIENTE)

    # dedupe por (Link, Palavra-chave, Cliente)
    link_idx    = COLS_CLIENTE.index("Link")
    palavra_idx = COLS_CLIENTE.index("Palavra-chave")
    cliente_idx = COLS_CLIENTE.index("Cliente")

    all_vals = ws.get_all_values()
    existing = set()
    if len(all_vals) > 1:
        for r in all_vals[1:]:
            if len(r) > link_idx:
                existing.add((r[link_idx].strip(),
                              r[palavra_idx].strip() if len(r) > palavra_idx else "",
                              r[cliente_idx].strip() if len(r) > cliente_idx else ""))
    new = [r for r in rows if (r[link_idx].strip(), r[palavra_idx].strip(), r[cliente_idx].strip()) not in existing]
    if not new:
        print(f"[{sheet_name}] nada novo.")
        return

    ws.insert_rows(new, row=2, value_input_option="USER_ENTERED")
    print(f"[{sheet_name}] +{len(new)} linhas.")

def salva_por_cliente(por_cliente: dict):
    plan_id = os.getenv("PLANILHA_CLIENTES")
    if not plan_id:
        print("PLANILHA_CLIENTES n√£o definido; pulando sa√≠da por cliente.")
        return
    gc = _gs_client_from_env()
    sh = gc.open_by_key(plan_id)

    # Garante exist√™ncia das abas
    for cli in CLIENT_KEYWORDS.keys():
        try:
            ws = sh.worksheet(cli)
            _ensure_header(ws, COLS_CLIENTE)
        except gspread.WorksheetNotFound:
            ws = sh.add_worksheet(title=cli, rows="2", cols=len(COLS_CLIENTE))
            _ensure_header(ws, COLS_CLIENTE)

    for cli, rows in (por_cliente or {}).items():
        _append_dedupe_por_cliente(sh, cli, rows)

# ============================================================
# E-mail (Brevo) ‚Äî GERAL (j√° existente)
# ============================================================
EMAIL_RE = re.compile(r'<?("?)([^"\s<>@]+@[^"\s<>@]+\.[^"\s<>@]+)\1>?$')

def _sanitize_emails(raw_list: str):
    if not raw_list:
        return []
    parts = re.split(r'[,\n;]+', raw_list)
    emails, seen = [], set()
    for it in parts:
        s = unicodedata.normalize("NFKC", it)
        s = re.sub(r'[\u200B-\u200D\uFEFF]', '', s).strip().strip("'").strip('"')
        if not s:
            continue
        m = EMAIL_RE.match(s)
        candidate = (m.group(2) if m else s).strip()
        if re.match(r"^[^@\s]+@[^@\s]+\.[^@\s]+$", candidate) and candidate.lower() not in seen:
            seen.add(candidate.lower()); emails.append(candidate.lower())
    return emails

def envia_email_brevo(palavras_raspadas):
    if not palavras_raspadas:
        print('Sem palavras encontradas para enviar (geral).')
        return
    print('Enviando e-mail via Brevo (geral)...')

    api_key = os.getenv('BREVO_API_KEY')
    sender_email = os.getenv('EMAIL')
    raw_dest = os.getenv('DESTINATARIOS', '')
    if not (api_key and sender_email and raw_dest):
        print("Dados de e-mail incompletos; pulando envio.")
        return

    destinatarios = _sanitize_emails(raw_dest)
    data = datetime.now().strftime('%d-%m-%Y')
    titulo = f'Busca DOU do dia {data}'
    planilha_url = f'https://docs.google.com/spreadsheets/d/{os.getenv("PLANILHA")}/edit?gid=0'

    parts = [
        "<html><body>",
        "<h1>Consulta ao Di√°rio Oficial da Uni√£o</h1>",
        f"<p>As mat√©rias encontradas no dia {data} est√£o listadas a seguir e j√° foram armazenadas na ",
        f'<a href="{planilha_url}" target="_blank">planilha</a>.</p>'
    ]
    for palavra, lista in (palavras_raspadas or {}).items():
        if lista:
            parts.append(f"<h2>{palavra}</h2><ul>")
            for r in lista:
                link = r.get('href', '#')
                title = r.get('title', '(sem t√≠tulo)')
                parts.append(f"<li><a href='{link}'>{title}</a></li>")
            parts.append("</ul>")
    parts.append("</body></html>")
    html = "".join(parts)

    cfg = Configuration(); cfg.api_key['api-key'] = api_key
    api = TransactionalEmailsApi(ApiClient(configuration=cfg))
    for dest in destinatarios:
        try:
            api.send_transac_email(SendSmtpEmail(
                to=[{"email": dest}],
                sender={"email": sender_email},
                subject=titulo,
                html_content=html
            ))
            print(f"‚úÖ E-mail enviado para {dest}")
        except (ApiException, Exception) as e:
            print(f"‚ùå Falha ao enviar para {dest}: {e}")

# ============================================================
# E-mail (Brevo) ‚Äî POR CLIENTE (NOVO)
# ============================================================
def envia_email_brevo_clientes(por_cliente: dict):
    """
    Envia e-mail agrupado por Cliente -> Palavra-chave -> Itens.
    Usa DESTINATARIOS_CLIENTES (se existir) ou fallback para DESTINATARIOS.
    """
    # checa se h√° algum conte√∫do
    has_any = any(por_cliente.get(cli) for cli in por_cliente or {})
    if not has_any:
        print("Sem itens por cliente para enviar.")
        return

    api_key = os.getenv('BREVO_API_KEY')
    sender_email = os.getenv('EMAIL')
    raw_dest = os.getenv('DESTINATARIOS_CLIENTES') or os.getenv('DESTINATARIOS', '')
    if not (api_key and sender_email and raw_dest):
        print("Dados de e-mail (clientes) incompletos; pulando envio.")
        return

    destinatarios = _sanitize_emails(raw_dest)
    data = datetime.now().strftime('%d-%m-%Y')
    titulo = f'DOU ‚Äì Clientes ‚Äì {data}'

    # link da planilha por clientes
    planilha_clientes_id = os.getenv("PLANILHA_CLIENTES")
    planilha_clientes_url = f'https://docs.google.com/spreadsheets/d/{planilha_clientes_id}/edit' if planilha_clientes_id else "#"

    # monta HTML agrupado
    parts = [
        "<html><body>",
        f"<h2>Resultados do Di√°rio Oficial ‚Äì {data}</h2>",
        "<p>As ocorr√™ncias j√° foram registradas por cliente. Seguem os destaques:</p>"
    ]

    # agrupa por cliente -> keyword
    for cliente, rows in (por_cliente or {}).items():
        if not rows:
            continue
        parts.append(f"<h3>{cliente}</h3>")
        # rows: [Data, Cliente, Palavra-chave, Portaria, Link, Resumo, Conte√∫do]
        # reagrupa por palavra
        by_kw = {}
        for row in rows:
            kw = row[2] or "(sem palavra-chave)"
            by_kw.setdefault(kw, []).append(row)

        for kw, itens in by_kw.items():
            parts.append(f"<h4>Palavra-chave: {kw}</h4><ul>")
            for r in itens:
                link = r[4] or "#"
                titulo = r[3] or "(sem t√≠tulo)"
                resumo = r[5] or ""
                parts.append(f"<li><a href='{link}'>{titulo}</a><br><em>Resumo: {resumo}</em></li>")
            parts.append("</ul>")

    parts.append(
        f'<p>üìä Veja a <a href="{planilha_clientes_url}" target="_blank">planilha por cliente</a> para o conte√∫do completo.</p>'
    )
    parts.append("</body></html>")
    html = "".join(parts)

    cfg = Configuration(); cfg.api_key['api-key'] = api_key
    api = TransactionalEmailsApi(ApiClient(configuration=cfg))
    for dest in destinatarios:
        try:
            api.send_transac_email(SendSmtpEmail(
                to=[{"email": dest}],
                sender={"email": sender_email},
                subject=titulo,
                html_content=html
            ))
            print(f"‚úÖ E-mail (clientes) enviado para {dest}")
        except (ApiException, Exception) as e:
            print(f"‚ùå Falha ao enviar (clientes) para {dest}: {e}")

# ============================================================
# Execu√ß√£o principal
# ============================================================
if __name__ == "__main__":
    conteudo = raspa_dou()

    # 1) Planilha geral
    geral = procura_termos(conteudo)
    salva_na_base(geral)
    envia_email_brevo(geral)  # e-mail s√≥ do geral

    # 2) Planilha por cliente (uma aba por sigla)
    por_cliente = procura_termos_clientes(conteudo)
    salva_por_cliente(por_cliente)
    # e-mail por cliente (apenas se houver itens)
    envia_email_brevo_clientes(por_cliente)
